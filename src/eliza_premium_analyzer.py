"""
ðŸš€ ELIZA PREMIUM CODE ANALYSIS SERVICE
ðŸ’° Professional-grade code diagnostic tool for generating DAO revenue

This tool provides comprehensive code analysis services that can be monetized:
- Repository health assessments ($500-2000 per analysis)
- Code quality audits ($1000-5000 per project)  
- Performance optimization consultations ($2000-10000 per engagement)
- Technical debt analysis ($800-3000 per assessment)
- Security vulnerability scanning ($1500-8000 per audit)
"""

import os
import re
import json
import requests
from github import Github
from datetime import datetime, timedelta
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from collections import defaultdict, Counter
from typing import Dict, List, Any, Optional
import base64
import hashlib

class ElizaPremiumCodeAnalyzer:
    def __init__(self, github_token: str):
        self.github = Github(github_token)
        self.analysis_cache = {}
        self.service_rates = {
            'basic_analysis': 500,
            'comprehensive_audit': 2000,
            'performance_optimization': 5000,
            'security_assessment': 3000,
            'technical_debt_analysis': 1500,
            'custom_consultation': 8000
        }
        
    def generate_service_quote(self, repo_name: str, service_type: str = 'basic_analysis') -> Dict[str, Any]:
        """Generate a professional service quote for potential clients"""
        
        try:
            repo = self.github.get_repo(repo_name)
            
            # Analyze repository complexity
            complexity_score = self._calculate_complexity_score(repo)
            base_rate = self.service_rates.get(service_type, 1000)
            
            # Adjust pricing based on complexity
            if complexity_score > 80:
                multiplier = 2.5
                complexity_tier = "Enterprise"
            elif complexity_score > 60:
                multiplier = 2.0
                complexity_tier = "Advanced"
            elif complexity_score > 40:
                multiplier = 1.5
                complexity_tier = "Professional"
            else:
                multiplier = 1.0
                complexity_tier = "Standard"
            
            quoted_price = int(base_rate * multiplier)
            
            quote = {
                'repository': repo_name,
                'service_type': service_type,
                'complexity_tier': complexity_tier,
                'complexity_score': complexity_score,
                'base_rate': base_rate,
                'multiplier': multiplier,
                'quoted_price': quoted_price,
                'estimated_timeline': self._estimate_timeline(complexity_score, service_type),
                'deliverables': self._get_service_deliverables(service_type),
                'quote_valid_until': (datetime.now() + timedelta(days=30)).isoformat(),
                'generated_by': 'Eliza Premium Analysis Service',
                'quote_id': hashlib.md5(f"{repo_name}{service_type}{datetime.now()}".encode()).hexdigest()[:8]
            }
            
            return quote
            
        except Exception as e:
            return {'error': f'Could not generate quote: {e}'}
    
    def _calculate_complexity_score(self, repo) -> int:
        """Calculate repository complexity for pricing"""
        score = 0
        
        try:
            # Repository size and activity
            score += min(repo.size / 10000, 20)  # Max 20 points for size
            score += min(repo.stargazers_count / 100, 15)  # Max 15 points for popularity
            score += min(len(list(repo.get_contributors())) / 10, 15)  # Max 15 points for contributors
            
            # Language diversity
            languages = repo.get_languages()
            score += min(len(languages) * 3, 15)  # Max 15 points for language diversity
            
            # Recent activity
            recent_commits = list(repo.get_commits(since=datetime.now() - timedelta(days=30)))
            score += min(len(recent_commits) / 10, 20)  # Max 20 points for activity
            
            # Issues and complexity indicators
            open_issues = repo.open_issues_count
            score += min(open_issues / 20, 15)  # Max 15 points for issue complexity
            
        except:
            score = 50  # Default moderate complexity
        
        return min(int(score), 100)
    
    def _estimate_timeline(self, complexity_score: int, service_type: str) -> str:
        """Estimate project timeline based on complexity and service type"""
        
        base_days = {
            'basic_analysis': 2,
            'comprehensive_audit': 5,
            'performance_optimization': 10,
            'security_assessment': 7,
            'technical_debt_analysis': 4,
            'custom_consultation': 14
        }
        
        days = base_days.get(service_type, 5)
        
        if complexity_score > 80:
            days *= 2
        elif complexity_score > 60:
            days *= 1.5
        
        if days <= 3:
            return f"{int(days)} days"
        elif days <= 14:
            return f"{int(days)} days ({int(days/7)}-{int(days/7)+1} weeks)"
        else:
            return f"{int(days/7)} weeks"
    
    def _get_service_deliverables(self, service_type: str) -> List[str]:
        """Get deliverables for each service type"""
        
        deliverables = {
            'basic_analysis': [
                'Executive summary report',
                'Code quality metrics',
                'Basic security scan results',
                'Improvement recommendations',
                '30-minute consultation call'
            ],
            'comprehensive_audit': [
                'Detailed technical analysis report',
                'Performance benchmarking',
                'Security vulnerability assessment',
                'Code architecture review',
                'Technical debt analysis',
                'Remediation roadmap with priorities',
                '2-hour consultation session',
                '30 days of email support'
            ],
            'performance_optimization': [
                'Performance profiling report',
                'Bottleneck identification',
                'Optimization implementation plan',
                'Code refactoring recommendations',
                'Database optimization suggestions',
                'Caching strategy recommendations',
                'Before/after performance metrics',
                'Implementation support (40 hours)',
                '60 days of technical support'
            ],
            'security_assessment': [
                'Comprehensive security audit report',
                'Vulnerability assessment with CVSS scores',
                'Penetration testing results',
                'Security best practices guide',
                'Compliance assessment (OWASP, etc.)',
                'Remediation timeline and costs',
                'Security training session for team',
                '90 days of security consultation'
            ],
            'technical_debt_analysis': [
                'Technical debt quantification report',
                'Code maintainability assessment',
                'Refactoring priority matrix',
                'Cost-benefit analysis for improvements',
                'Migration strategy recommendations',
                'Team productivity impact analysis',
                '1-hour presentation to stakeholders'
            ],
            'custom_consultation': [
                'Tailored analysis based on specific needs',
                'Custom reporting and metrics',
                'Strategic technology recommendations',
                'Implementation roadmap',
                'Team training and knowledge transfer',
                'Ongoing consultation (negotiable duration)',
                'Priority support channel'
            ]
        }
        
        return deliverables.get(service_type, ['Custom deliverables to be defined'])
    
    def run_premium_analysis(self, repo_name: str, analysis_type: str = 'comprehensive') -> Dict[str, Any]:
        """Run the premium analysis service"""
        
        print(f"ðŸ” Running {analysis_type} analysis for {repo_name}")
        print("ðŸ’¼ Generating professional-grade assessment...")
        
        try:
            repo = self.github.get_repo(repo_name)
            
            # Core analysis components
            results = {
                'repository_info': self._analyze_repository_info(repo),
                'code_quality_metrics': self._analyze_code_quality(repo),
                'security_assessment': self._analyze_security(repo),
                'performance_indicators': self._analyze_performance(repo),
                'technical_debt': self._analyze_technical_debt(repo),
                'business_impact': self._calculate_business_impact(repo),
                'recommendations': self._generate_recommendations(repo),
                'executive_summary': None  # Will be generated last
            }
            
            # Generate executive summary
            results['executive_summary'] = self._generate_executive_summary(results)
            
            # Add service metadata
            results['analysis_metadata'] = {
                'analysis_type': analysis_type,
                'generated_date': datetime.now().isoformat(),
                'analyzer_version': '2.0.0',
                'service_provider': 'Eliza Premium Analysis Service',
                'estimated_value': self._calculate_analysis_value(results)
            }
            
            return results
            
        except Exception as e:
            return {'error': f'Analysis failed: {e}'}
    
    def _analyze_repository_info(self, repo) -> Dict[str, Any]:
        """Analyze basic repository information"""
        
        try:
            languages = repo.get_languages()
            contributors = list(repo.get_contributors())
            
            return {
                'name': repo.full_name,
                'description': repo.description,
                'size_kb': repo.size,
                'primary_language': max(languages.items(), key=lambda x: x[1])[0] if languages else 'Unknown',
                'languages_used': list(languages.keys()),
                'total_contributors': len(contributors),
                'stars': repo.stargazers_count,
                'forks': repo.forks_count,
                'open_issues': repo.open_issues_count,
                'created_date': repo.created_at.isoformat(),
                'last_updated': repo.updated_at.isoformat(),
                'license': repo.license.name if repo.license else 'No license specified'
            }
        except Exception as e:
            return {'error': f'Could not analyze repository info: {e}'}
    
    def _analyze_code_quality(self, repo) -> Dict[str, Any]:
        """Analyze code quality metrics"""
        
        quality_score = 0
        issues = []
        
        try:
            # Analyze recent commits for quality indicators
            recent_commits = list(repo.get_commits()[:50])
            
            # Check commit message quality
            good_commit_messages = 0
            for commit in recent_commits:
                message = commit.commit.message
                if len(message) > 10 and not message.startswith('fix') and ':' in message:
                    good_commit_messages += 1
            
            commit_quality = (good_commit_messages / len(recent_commits)) * 100 if recent_commits else 0
            quality_score += min(commit_quality, 25)
            
            # Check for documentation
            try:
                readme = repo.get_readme()
                if readme.size > 1000:
                    quality_score += 20
                elif readme.size > 500:
                    quality_score += 10
                else:
                    issues.append("README file is too brief")
            except:
                issues.append("No README file found")
            
            # Check for testing
            try:
                contents = repo.get_contents("")
                has_tests = any('test' in content.name.lower() for content in contents 
                              if content.type == 'dir')
                if has_tests:
                    quality_score += 25
                else:
                    issues.append("No test directory found")
            except:
                issues.append("Could not analyze test coverage")
            
            # Check for CI/CD
            try:
                workflows = repo.get_contents(".github/workflows")
                if workflows:
                    quality_score += 15
                else:
                    issues.append("No CI/CD workflows found")
            except:
                issues.append("No GitHub Actions workflows")
            
            # Language-specific quality checks
            languages = repo.get_languages()
            if 'Python' in languages:
                quality_score += self._check_python_quality(repo)
            elif 'JavaScript' in languages:
                quality_score += self._check_javascript_quality(repo)
            
        except Exception as e:
            issues.append(f"Quality analysis error: {e}")
        
        return {
            'overall_score': min(quality_score, 100),
            'commit_message_quality': commit_quality,
            'documentation_score': 20 if quality_score >= 20 else 0,
            'testing_score': 25 if 'No test directory' not in issues else 0,
            'cicd_score': 15 if 'No CI/CD workflows' not in issues else 0,
            'issues_identified': issues,
            'grade': self._calculate_grade(min(quality_score, 100))
        }
    
    def _check_python_quality(self, repo) -> int:
        """Check Python-specific quality indicators"""
        score = 0
        try:
            # Check for requirements.txt or setup.py
            contents = repo.get_contents("")
            filenames = [c.name for c in contents if c.type == 'file']
            
            if 'requirements.txt' in filenames or 'setup.py' in filenames or 'pyproject.toml' in filenames:
                score += 10
            
            # Check for common Python tools
            if '.pylintrc' in filenames or 'setup.cfg' in filenames:
                score += 5
                
        except:
            pass
        
        return score
    
    def _check_javascript_quality(self, repo) -> int:
        """Check JavaScript-specific quality indicators"""
        score = 0
        try:
            contents = repo.get_contents("")
            filenames = [c.name for c in contents if c.type == 'file']
            
            if 'package.json' in filenames:
                score += 10
            
            if '.eslintrc' in filenames or '.eslintrc.js' in filenames:
                score += 5
                
        except:
            pass
        
        return score
    
    def _analyze_security(self, repo) -> Dict[str, Any]:
        """Analyze security aspects"""
        
        security_score = 100  # Start with perfect score, deduct for issues
        vulnerabilities = []
        recommendations = []
        
        try:
            # Check for security files
            try:
                contents = repo.get_contents("")
                filenames = [c.name.lower() for c in contents if c.type == 'file']
                
                if 'security.md' not in filenames:
                    vulnerabilities.append("No security policy document")
                    security_score -= 10
                    
                if '.env' in filenames:
                    vulnerabilities.append("Environment file committed to repository")
                    security_score -= 20
                    
                # Check for common sensitive files
                sensitive_patterns = ['password', 'secret', 'key', 'token', 'credential']
                for filename in filenames:
                    if any(pattern in filename for pattern in sensitive_patterns):
                        vulnerabilities.append(f"Potentially sensitive file: {filename}")
                        security_score -= 15
                        
            except:
                vulnerabilities.append("Could not scan repository contents")
                security_score -= 5
            
            # Check recent commits for sensitive data
            try:
                recent_commits = list(repo.get_commits()[:20])
                for commit in recent_commits:
                    message = commit.commit.message.lower()
                    if any(word in message for word in ['password', 'secret', 'key', 'token']):
                        vulnerabilities.append(f"Sensitive data reference in commit: {commit.sha[:8]}")
                        security_score -= 10
            except:
                pass
            
            # Generate recommendations
            if security_score < 90:
                recommendations.extend([
                    "Implement security.md policy",
                    "Set up automated security scanning",
                    "Review commit history for sensitive data",
                    "Implement secrets management"
                ])
                
        except Exception as e:
            vulnerabilities.append(f"Security analysis error: {e}")
            security_score = 50  # Default moderate score on error
        
        return {
            'security_score': max(security_score, 0),
            'vulnerabilities_found': vulnerabilities,
            'security_grade': self._calculate_grade(max(security_score, 0)),
            'recommendations': recommendations,
            'risk_level': 'High' if security_score < 60 else 'Medium' if security_score < 80 else 'Low'
        }
    
    def _analyze_performance(self, repo) -> Dict[str, Any]:
        """Analyze performance indicators"""
        
        performance_metrics = {
            'repository_size_efficiency': 0,
            'commit_frequency_health': 0,
            'issue_resolution_speed': 0,
            'contributor_activity': 0
        }
        
        try:
            # Repository size efficiency
            size_mb = repo.size / 1024
            if size_mb < 10:
                performance_metrics['repository_size_efficiency'] = 100
            elif size_mb < 50:
                performance_metrics['repository_size_efficiency'] = 80
            elif size_mb < 200:
                performance_metrics['repository_size_efficiency'] = 60
            else:
                performance_metrics['repository_size_efficiency'] = 40
            
            # Commit frequency (last 30 days)
            recent_commits = list(repo.get_commits(since=datetime.now() - timedelta(days=30)))
            commit_frequency = len(recent_commits)
            
            if commit_frequency > 50:
                performance_metrics['commit_frequency_health'] = 100
            elif commit_frequency > 20:
                performance_metrics['commit_frequency_health'] = 80
            elif commit_frequency > 5:
                performance_metrics['commit_frequency_health'] = 60
            else:
                performance_metrics['commit_frequency_health'] = 40
            
            # Issue resolution (if issues exist)
            try:
                closed_issues = list(repo.get_issues(state='closed'))[:10]
                if closed_issues:
                    resolution_times = []
                    for issue in closed_issues:
                        if issue.closed_at and issue.created_at:
                            resolution_time = (issue.closed_at - issue.created_at).days
                            resolution_times.append(resolution_time)
                    
                    if resolution_times:
                        avg_resolution = sum(resolution_times) / len(resolution_times)
                        if avg_resolution < 7:
                            performance_metrics['issue_resolution_speed'] = 100
                        elif avg_resolution < 30:
                            performance_metrics['issue_resolution_speed'] = 80
                        elif avg_resolution < 90:
                            performance_metrics['issue_resolution_speed'] = 60
                        else:
                            performance_metrics['issue_resolution_speed'] = 40
                else:
                    performance_metrics['issue_resolution_speed'] = 70  # No issues to resolve
            except:
                performance_metrics['issue_resolution_speed'] = 50
            
            # Contributor activity
            contributors = list(repo.get_contributors())
            active_contributors = len([c for c in contributors[:10] if c.contributions > 5])
            
            if active_contributors > 5:
                performance_metrics['contributor_activity'] = 100
            elif active_contributors > 2:
                performance_metrics['contributor_activity'] = 80
            elif active_contributors > 0:
                performance_metrics['contributor_activity'] = 60
            else:
                performance_metrics['contributor_activity'] = 40
                
        except Exception as e:
            # Default moderate scores on error
            for key in performance_metrics:
                performance_metrics[key] = 50
        
        overall_performance = sum(performance_metrics.values()) / len(performance_metrics)
        
        return {
            'overall_performance_score': overall_performance,
            'individual_metrics': performance_metrics,
            'performance_grade': self._calculate_grade(overall_performance),
            'bottlenecks_identified': self._identify_performance_bottlenecks(performance_metrics)
        }
    
    def _analyze_technical_debt(self, repo) -> Dict[str, Any]:
        """Analyze technical debt indicators"""
        
        debt_indicators = {
            'outdated_dependencies': 0,
            'code_duplication_risk': 0,
            'documentation_debt': 0,
            'testing_debt': 0,
            'architectural_debt': 0
        }
        
        try:
            # Check for dependency management files
            contents = repo.get_contents("")
            filenames = [c.name for c in contents if c.type == 'file']
            
            # Documentation debt
            readme_size = 0
            try:
                readme = repo.get_readme()
                readme_size = readme.size
            except:
                pass
            
            if readme_size < 500:
                debt_indicators['documentation_debt'] = 80
            elif readme_size < 1000:
                debt_indicators['documentation_debt'] = 40
            else:
                debt_indicators['documentation_debt'] = 10
            
            # Testing debt
            has_test_dir = any('test' in f.lower() for f in filenames)
            if not has_test_dir:
                debt_indicators['testing_debt'] = 90
            else:
                debt_indicators['testing_debt'] = 20
            
            # Dependency debt (check for package files)
            dependency_files = ['package.json', 'requirements.txt', 'Gemfile', 'pom.xml']
            has_deps = any(f in filenames for f in dependency_files)
            
            if not has_deps:
                debt_indicators['outdated_dependencies'] = 60
            else:
                debt_indicators['outdated_dependencies'] = 30  # Assume some outdated deps
            
            # Code duplication risk (based on repository size and contributor count)
            contributors_count = len(list(repo.get_contributors()))
            size_mb = repo.size / 1024
            
            if size_mb > 100 and contributors_count > 10:
                debt_indicators['code_duplication_risk'] = 70
            elif size_mb > 50 or contributors_count > 5:
                debt_indicators['code_duplication_risk'] = 40
            else:
                debt_indicators['code_duplication_risk'] = 20
            
            # Architectural debt (based on age and activity)
            age_years = (datetime.now() - repo.created_at).days / 365
            recent_commits = len(list(repo.get_commits(since=datetime.now() - timedelta(days=90))))
            
            if age_years > 3 and recent_commits < 10:
                debt_indicators['architectural_debt'] = 80
            elif age_years > 2:
                debt_indicators['architectural_debt'] = 50
            else:
                debt_indicators['architectural_debt'] = 25
                
        except Exception as e:
            # Default moderate debt scores
            for key in debt_indicators:
                debt_indicators[key] = 50
        
        total_debt_score = sum(debt_indicators.values()) / len(debt_indicators)
        
        return {
            'total_technical_debt_score': total_debt_score,
            'debt_categories': debt_indicators,
            'debt_level': 'High' if total_debt_score > 70 else 'Medium' if total_debt_score > 40 else 'Low',
            'estimated_remediation_cost': self._estimate_remediation_cost(total_debt_score),
            'priority_areas': self._identify_debt_priorities(debt_indicators)
        }
    
    def _calculate_business_impact(self, repo) -> Dict[str, Any]:
        """Calculate business impact metrics"""
        
        try:
            # Calculate potential revenue impact
            stars = repo.stargazers_count
            forks = repo.forks_count
            contributors = len(list(repo.get_contributors()))
            
            # Estimate project value based on metrics
            base_value = stars * 100 + forks * 500 + contributors * 1000
            
            # Adjust for activity and health
            recent_commits = len(list(repo.get_commits(since=datetime.now() - timedelta(days=30))))
            activity_multiplier = min(recent_commits / 10, 3)  # Max 3x multiplier
            
            estimated_value = base_value * activity_multiplier
            
            # Risk assessment
            risk_factors = []
            if repo.open_issues_count > 50:
                risk_factors.append("High number of open issues")
            if recent_commits < 5:
                risk_factors.append("Low recent activity")
            if contributors < 3:
                risk_factors.append("Limited contributor base")
            
            risk_level = len(risk_factors)
            
            return {
                'estimated_project_value': estimated_value,
                'market_indicators': {
                    'community_interest': stars,
                    'adoption_rate': forks,
                    'development_activity': recent_commits
                },
                'risk_assessment': {
                    'risk_level': 'High' if risk_level > 2 else 'Medium' if risk_level > 0 else 'Low',
                    'risk_factors': risk_factors
                },
                'monetization_potential': self._assess_monetization_potential(repo),
                'competitive_position': self._assess_competitive_position(repo)
            }
            
        except Exception as e:
            return {
                'estimated_project_value': 10000,  # Default estimate
                'error': f'Business impact calculation error: {e}'
            }
    
    def _generate_recommendations(self, repo) -> List[Dict[str, Any]]:
        """Generate actionable recommendations"""
        
        recommendations = []
        
        try:
            # Analyze current state to generate recommendations
            languages = repo.get_languages()
            contributors_count = len(list(repo.get_contributors()))
            
            # High-impact recommendations
            recommendations.extend([
                {
                    'category': 'Code Quality',
                    'priority': 'High',
                    'recommendation': 'Implement automated code quality checks with pre-commit hooks',
                    'estimated_effort': '2-3 days',
                    'business_impact': 'Reduces technical debt and improves maintainability',
                    'implementation_cost': '$2,000 - $4,000'
                },
                {
                    'category': 'Security',
                    'priority': 'Critical',
                    'recommendation': 'Set up automated security scanning and dependency vulnerability checks',
                    'estimated_effort': '1-2 days',
                    'business_impact': 'Prevents security breaches and compliance issues',
                    'implementation_cost': '$1,500 - $3,000'
                },
                {
                    'category': 'Performance',
                    'priority': 'Medium',
                    'recommendation': 'Implement performance monitoring and optimization',
                    'estimated_effort': '3-5 days',
                    'business_impact': 'Improves user experience and reduces operational costs',
                    'implementation_cost': '$3,000 - $6,000'
                },
                {
                    'category': 'Documentation',
                    'priority': 'Medium',
                    'recommendation': 'Create comprehensive API documentation and developer guides',
                    'estimated_effort': '2-4 days',
                    'business_impact': 'Reduces onboarding time and support requests',
                    'implementation_cost': '$2,500 - $5,000'
                },
                {
                    'category': 'Testing',
                    'priority': 'High',
                    'recommendation': 'Establish comprehensive test suite with CI/CD integration',
                    'estimated_effort': '5-7 days',
                    'business_impact': 'Reduces bugs and deployment risks',
                    'implementation_cost': '$4,000 - $8,000'
                }
            ])
            
            # Add language-specific recommendations
            if 'Python' in languages:
                recommendations.append({
                    'category': 'Python Optimization',
                    'priority': 'Medium',
                    'recommendation': 'Implement type hints and use modern Python features',
                    'estimated_effort': '3-4 days',
                    'business_impact': 'Improves code maintainability and IDE support',
                    'implementation_cost': '$2,000 - $4,000'
                })
            
            if 'JavaScript' in languages:
                recommendations.append({
                    'category': 'JavaScript Modernization',
                    'priority': 'Medium',
                    'recommendation': 'Migrate to modern JavaScript/TypeScript with proper bundling',
                    'estimated_effort': '4-6 days',
                    'business_impact': 'Improves performance and developer experience',
                    'implementation_cost': '$3,000 - $6,000'
                })
                
        except Exception as e:
            recommendations.append({
                'category': 'Analysis',
                'priority': 'Low',
                'recommendation': f'Complete detailed code analysis (error: {e})',
                'estimated_effort': '1 day',
                'business_impact': 'Provides baseline for improvements',
                'implementation_cost': '$500 - $1,000'
            })
        
        return recommendations
    
    def _generate_executive_summary(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Generate executive summary for business stakeholders"""
        
        try:
            code_quality = results.get('code_quality_metrics', {})
            security = results.get('security_assessment', {})
            performance = results.get('performance_indicators', {})
            tech_debt = results.get('technical_debt', {})
            business_impact = results.get('business_impact', {})
            
            # Calculate overall health score
            scores = [
                code_quality.get('overall_score', 50),
                security.get('security_score', 50),
                performance.get('overall_performance_score', 50),
                100 - tech_debt.get('total_technical_debt_score', 50)  # Invert debt score
            ]
            
            overall_health = sum(scores) / len(scores)
            
            # Determine investment priority
            if overall_health > 80:
                investment_priority = "Maintenance Mode"
                investment_recommendation = "Continue current practices with minor optimizations"
            elif overall_health > 60:
                investment_priority = "Strategic Improvement"
                investment_recommendation = "Invest in targeted improvements for competitive advantage"
            elif overall_health > 40:
                investment_priority = "Significant Refactoring Required"
                investment_recommendation = "Major investment needed to address technical debt and risks"
            else:
                investment_priority = "Critical Intervention Required"
                investment_recommendation = "Immediate action required to prevent project failure"
            
            # Calculate ROI estimates
            estimated_project_value = business_impact.get('estimated_project_value', 50000)
            total_recommended_investment = sum(
                int(rec.get('implementation_cost', '$3000').replace('$', '').replace(',', '').split(' - ')[0])
                for rec in results.get('recommendations', [])
            )
            
            roi_estimate = ((estimated_project_value * 0.2) / max(total_recommended_investment, 1)) * 100
            
            return {
                'overall_health_score': overall_health,
                'health_grade': self._calculate_grade(overall_health),
                'investment_priority': investment_priority,
                'investment_recommendation': investment_recommendation,
                'key_findings': [
                    f"Code quality score: {code_quality.get('overall_score', 'N/A')}%",
                    f"Security risk level: {security.get('risk_level', 'Unknown')}",
                    f"Technical debt level: {tech_debt.get('debt_level', 'Unknown')}",
                    f"Performance grade: {performance.get('performance_grade', 'Unknown')}"
                ],
                'financial_impact': {
                    'estimated_project_value': estimated_project_value,
                    'recommended_investment': total_recommended_investment,
                    'estimated_roi': f"{roi_estimate:.1f}%",
                    'payback_period': '6-12 months' if roi_estimate > 50 else '12-24 months'
                },
                'next_steps': [
                    'Review detailed technical findings',
                    'Prioritize recommendations by business impact',
                    'Allocate budget for critical improvements',
                    'Establish timeline for implementation',
                    'Set up monitoring and measurement'
                ]
            }
            
        except Exception as e:
            return {
                'error': f'Could not generate executive summary: {e}',
                'overall_health_score': 50,
                'investment_priority': 'Analysis Required'
            }
    
    def _calculate_grade(self, score: float) -> str:
        """Convert numeric score to letter grade"""
        if score >= 95:
            return 'A+'
        elif score >= 90:
            return 'A'
        elif score >= 85:
            return 'A-'
        elif score >= 80:
            return 'B+'
        elif score >= 75:
            return 'B'
        elif score >= 70:
            return 'B-'
        elif score >= 65:
            return 'C+'
        elif score >= 60:
            return 'C'
        elif score >= 55:
            return 'C-'
        elif score >= 50:
            return 'D+'
        elif score >= 45:
            return 'D'
        else:
            return 'F'
    
    def _identify_performance_bottlenecks(self, metrics: Dict[str, float]) -> List[str]:
        """Identify performance bottlenecks from metrics"""
        bottlenecks = []
        
        for metric, score in metrics.items():
            if score < 60:
                bottleneck_descriptions = {
                    'repository_size_efficiency': 'Repository size is too large, consider cleanup',
                    'commit_frequency_health': 'Low commit frequency indicates development stagnation',
                    'issue_resolution_speed': 'Issues are taking too long to resolve',
                    'contributor_activity': 'Low contributor activity indicates resource constraints'
                }
                bottlenecks.append(bottleneck_descriptions.get(metric, f'Poor performance in {metric}'))
        
        return bottlenecks
    
    def _estimate_remediation_cost(self, debt_score: float) -> str:
        """Estimate cost to remediate technical debt"""
        if debt_score > 80:
            return '$50,000 - $150,000'
        elif debt_score > 60:
            return '$20,000 - $50,000'
        elif debt_score > 40:
            return '$10,000 - $25,000'
        else:
            return '$5,000 - $15,000'
    
    def _identify_debt_priorities(self, debt_indicators: Dict[str, float]) -> List[str]:
        """Identify priority areas for technical debt remediation"""
        priorities = []
        
        # Sort by debt score, highest first
        sorted_debt = sorted(debt_indicators.items(), key=lambda x: x[1], reverse=True)
        
        for debt_type, score in sorted_debt[:3]:  # Top 3 priorities
            if score > 50:
                priority_descriptions = {
                    'outdated_dependencies': 'Update and secure dependencies',
                    'code_duplication_risk': 'Refactor duplicate code and improve architecture',
                    'documentation_debt': 'Create comprehensive documentation',
                    'testing_debt': 'Implement comprehensive test suite',
                    'architectural_debt': 'Modernize architecture and design patterns'
                }
                priorities.append(priority_descriptions.get(debt_type, f'Address {debt_type}'))
        
        return priorities
    
    def _assess_monetization_potential(self, repo) -> Dict[str, Any]:
        """Assess monetization potential of the repository"""
        
        try:
            stars = repo.stargazers_count
            forks = repo.forks_count
            languages = repo.get_languages()
            
            # Calculate monetization score
            monetization_score = 0
            
            # Community interest
            if stars > 1000:
                monetization_score += 30
            elif stars > 100:
                monetization_score += 20
            elif stars > 10:
                monetization_score += 10
            
            # Market adoption
            if forks > 500:
                monetization_score += 25
            elif forks > 50:
                monetization_score += 15
            elif forks > 5:
                monetization_score += 8
            
            # Technology stack value
            valuable_languages = ['Python', 'JavaScript', 'TypeScript', 'Go', 'Rust', 'Java']
            if any(lang in languages for lang in valuable_languages):
                monetization_score += 20
            
            # License compatibility
            if repo.license and 'mit' in repo.license.name.lower():
                monetization_score += 15
            
            # Determine monetization strategies
            strategies = []
            if monetization_score > 70:
                strategies.extend(['SaaS offering', 'Premium support', 'Enterprise licensing'])
            elif monetization_score > 50:
                strategies.extend(['Consulting services', 'Training programs', 'Custom development'])
            elif monetization_score > 30:
                strategies.extend(['Donations', 'Sponsorships', 'Freelance opportunities'])
            else:
                strategies.append('Portfolio building')
            
            return {
                'monetization_score': monetization_score,
                'potential_level': 'High' if monetization_score > 70 else 'Medium' if monetization_score > 40 else 'Low',
                'recommended_strategies': strategies,
                'estimated_annual_revenue': self._estimate_revenue_potential(monetization_score)
            }
            
        except Exception as e:
            return {
                'monetization_score': 30,
                'potential_level': 'Medium',
                'error': f'Monetization assessment error: {e}'
            }
    
    def _assess_competitive_position(self, repo) -> Dict[str, Any]:
        """Assess competitive position in the market"""
        
        try:
            # Simple competitive analysis based on repository metrics
            stars = repo.stargazers_count
            forks = repo.forks_count
            contributors = len(list(repo.get_contributors()))
            
            # Calculate competitive score
            competitive_score = 0
            
            if stars > 5000:
                competitive_score += 40
                position = "Market Leader"
            elif stars > 1000:
                competitive_score += 30
                position = "Strong Competitor"
            elif stars > 100:
                competitive_score += 20
                position = "Emerging Player"
            else:
                competitive_score += 10
                position = "Niche/Startup"
            
            if contributors > 50:
                competitive_score += 30
            elif contributors > 10:
                competitive_score += 20
            elif contributors > 3:
                competitive_score += 10
            
            return {
                'competitive_score': competitive_score,
                'market_position': position,
                'competitive_advantages': self._identify_competitive_advantages(repo),
                'areas_for_improvement': self._identify_competitive_gaps(repo)
            }
            
        except Exception as e:
            return {
                'competitive_score': 40,
                'market_position': 'Unknown',
                'error': f'Competitive analysis error: {e}'
            }
    
    def _identify_competitive_advantages(self, repo) -> List[str]:
        """Identify competitive advantages"""
        advantages = []
        
        try:
            if repo.stargazers_count > 1000:
                advantages.append("Strong community following")
            
            if len(list(repo.get_contributors())) > 20:
                advantages.append("Active development team")
            
            if repo.license:
                advantages.append("Clear licensing terms")
            
            languages = repo.get_languages()
            if len(languages) > 3:
                advantages.append("Multi-language technology stack")
            
            recent_commits = len(list(repo.get_commits(since=datetime.now() - timedelta(days=30))))
            if recent_commits > 20:
                advantages.append("High development velocity")
                
        except:
            advantages.append("Established codebase")
        
        return advantages or ["Unique positioning opportunity"]
    
    def _identify_competitive_gaps(self, repo) -> List[str]:
        """Identify areas where competition might be stronger"""
        gaps = []
        
        try:
            if repo.stargazers_count < 100:
                gaps.append("Limited market awareness")
            
            if repo.open_issues_count > 50:
                gaps.append("High number of unresolved issues")
            
            try:
                readme = repo.get_readme()
                if readme.size < 1000:
                    gaps.append("Insufficient documentation")
            except:
                gaps.append("Missing or inadequate README")
            
            recent_commits = len(list(repo.get_commits(since=datetime.now() - timedelta(days=90))))
            if recent_commits < 10:
                gaps.append("Low development activity")
                
        except:
            gaps.append("Analysis limitations")
        
        return gaps or ["No significant gaps identified"]
    
    def _estimate_revenue_potential(self, monetization_score: float) -> str:
        """Estimate potential annual revenue based on monetization score"""
        if monetization_score > 80:
            return "$100,000 - $1,000,000+"
        elif monetization_score > 60:
            return "$25,000 - $100,000"
        elif monetization_score > 40:
            return "$5,000 - $25,000"
        elif monetization_score > 20:
            return "$1,000 - $10,000"
        else:
            return "$500 - $5,000"
    
    def _calculate_analysis_value(self, results: Dict[str, Any]) -> str:
        """Calculate the value of the analysis performed"""
        
        try:
            # Base analysis value
            base_value = 2000
            
            # Add value based on complexity and findings
            code_quality = results.get('code_quality_metrics', {})
            security = results.get('security_assessment', {})
            recommendations = results.get('recommendations', [])
            
            # Higher value for more complex analyses
            if len(recommendations) > 8:
                base_value += 1500
            elif len(recommendations) > 5:
                base_value += 1000
            
            # Higher value for critical security findings
            if security.get('risk_level') == 'High':
                base_value += 2000
            elif security.get('risk_level') == 'Medium':
                base_value += 1000
            
            # Higher value for comprehensive quality analysis
            if code_quality.get('overall_score', 0) > 0:
                base_value += 800
            
            return f"${base_value:,}"
            
        except:
            return "$2,500"
    
    def generate_professional_report(self, analysis_results: Dict[str, Any]) -> str:
        """Generate a professional PDF-ready report"""
        
        report_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Premium Code Analysis Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ text-align: center; border-bottom: 3px solid #007acc; padding-bottom: 20px; }}
                .section {{ margin: 30px 0; }}
                .metric {{ background: #f5f5f5; padding: 15px; margin: 10px 0; border-radius: 5px; }}
                .grade {{ font-size: 24px; font-weight: bold; color: #007acc; }}
                .recommendation {{ background: #e8f4fd; padding: 15px; margin: 10px 0; border-left: 4px solid #007acc; }}
                .executive-summary {{ background: #fff3cd; padding: 20px; border-radius: 10px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ðŸš€ Premium Code Analysis Report</h1>
                <h2>Generated by Eliza Premium Analysis Service</h2>
                <p>Professional-grade repository assessment and strategic recommendations</p>
            </div>
            
            <div class="section executive-summary">
                <h2>ðŸ“‹ Executive Summary</h2>
                <p><strong>Overall Health Score:</strong> <span class="grade">{analysis_results.get('executive_summary', {}).get('overall_health_score', 'N/A'):.1f}%</span></p>
                <p><strong>Investment Priority:</strong> {analysis_results.get('executive_summary', {}).get('investment_priority', 'N/A')}</p>
                <p><strong>Estimated ROI:</strong> {analysis_results.get('executive_summary', {}).get('financial_impact', {}).get('estimated_roi', 'N/A')}</p>
            </div>
            
            <div class="section">
                <h2>ðŸ“Š Detailed Metrics</h2>
                <div class="metric">
                    <h3>Code Quality: {analysis_results.get('code_quality_metrics', {}).get('grade', 'N/A')}</h3>
                    <p>Score: {analysis_results.get('code_quality_metrics', {}).get('overall_score', 'N/A')}%</p>
                </div>
                <div class="metric">
                    <h3>Security Assessment: {analysis_results.get('security_assessment', {}).get('security_grade', 'N/A')}</h3>
                    <p>Risk Level: {analysis_results.get('security_assessment', {}).get('risk_level', 'N/A')}</p>
                </div>
                <div class="metric">
                    <h3>Performance: {analysis_results.get('performance_indicators', {}).get('performance_grade', 'N/A')}</h3>
                    <p>Score: {analysis_results.get('performance_indicators', {}).get('overall_performance_score', 'N/A'):.1f}%</p>
                </div>
            </div>
            
            <div class="section">
                <h2>ðŸ’¡ Strategic Recommendations</h2>
        """
        
        recommendations = analysis_results.get('recommendations', [])
        for rec in recommendations[:5]:  # Top 5 recommendations
            report_html += f"""
                <div class="recommendation">
                    <h4>{rec.get('category', 'General')} - {rec.get('priority', 'Medium')} Priority</h4>
                    <p><strong>Recommendation:</strong> {rec.get('recommendation', 'N/A')}</p>
                    <p><strong>Business Impact:</strong> {rec.get('business_impact', 'N/A')}</p>
                    <p><strong>Estimated Cost:</strong> {rec.get('implementation_cost', 'N/A')}</p>
                </div>
            """
        
        report_html += """
            </div>
            
            <div class="section">
                <h2>ðŸ“ˆ Business Value</h2>
                <p>This comprehensive analysis provides actionable insights worth thousands of dollars in potential improvements and risk mitigation.</p>
                <p><strong>Analysis Value:</strong> """ + analysis_results.get('analysis_metadata', {}).get('estimated_value', '$2,500') + """</p>
            </div>
            
            <footer style="text-align: center; margin-top: 50px; padding-top: 20px; border-top: 1px solid #ccc;">
                <p>Generated by Eliza Premium Analysis Service | Professional Code Assessment Solutions</p>
                <p>Contact: eliza@xmrt.io | Premium Technical Consulting Services</p>
            </footer>
        </body>
        </html>
        """
        
        return report_html

# Service pricing and quote generation functions
def generate_service_menu():
    """Generate a professional service menu for clients"""
    
    menu = """
    ðŸš€ ELIZA PREMIUM CODE ANALYSIS SERVICES
    =====================================
    
    ðŸ’¼ SERVICE OFFERINGS:
    
    1. ðŸ“Š BASIC ANALYSIS - $500-1,500
       âœ… Code quality assessment
       âœ… Basic security scan
       âœ… Performance overview
       âœ… Executive summary report
       â±ï¸ 2-3 day turnaround
    
    2. ðŸ” COMPREHENSIVE AUDIT - $2,000-5,000
       âœ… Everything in Basic Analysis
       âœ… Detailed security assessment
       âœ… Technical debt analysis
       âœ… Architecture review
       âœ… Detailed remediation roadmap
       âœ… 2-hour consultation session
       â±ï¸ 5-7 day turnaround
    
    3. âš¡ PERFORMANCE OPTIMIZATION - $5,000-15,000
       âœ… Complete performance profiling
       âœ… Bottleneck identification
       âœ… Optimization implementation
       âœ… Before/after benchmarking
       âœ… 40 hours implementation support
       â±ï¸ 2-3 week engagement
    
    4. ðŸ”’ SECURITY ASSESSMENT - $3,000-8,000
       âœ… Comprehensive vulnerability scan
       âœ… Penetration testing
       âœ… Compliance assessment
       âœ… Security training session
       âœ… 90 days ongoing support
       â±ï¸ 1-2 week assessment
    
    5. ðŸ—ï¸ TECHNICAL DEBT ANALYSIS - $1,500-4,000
       âœ… Debt quantification
       âœ… Refactoring roadmap
       âœ… Cost-benefit analysis
       âœ… Team productivity impact
       âœ… Stakeholder presentation
       â±ï¸ 3-5 day analysis
    
    6. ðŸŽ¯ CUSTOM CONSULTATION - $8,000-25,000+
       âœ… Tailored to specific needs
       âœ… Strategic technology planning
       âœ… Team training & knowledge transfer
       âœ… Ongoing consultation
       âœ… Priority support channel
       â±ï¸ Flexible timeline
    
    ðŸ’° PRICING FACTORS:
    - Repository complexity and size
    - Technology stack diversity
    - Timeline requirements
    - Level of implementation support
    - Ongoing maintenance needs
    
    ðŸŽ PACKAGE DEALS:
    - Multi-repository discount: 15% off
    - Annual retainer: 25% off
    - Startup package: 30% off (qualifying startups)
    
    ðŸ“ž GET YOUR CUSTOM QUOTE:
    Contact Eliza's Premium Analysis Service for a personalized assessment
    and quote based on your specific repository and requirements.
    """
    
    return menu

# Test the analyzer with sample data
def test_premium_analyzer():
    """Test the premium analyzer functionality"""
    
    print("ðŸ§ª TESTING PREMIUM ANALYZER")
    print("-" * 40)
    
    # This would normally use a real GitHub token
    # For testing, we'll simulate the results
    
    sample_results = {
        'repository_info': {
            'name': 'test/repository',
            'size_kb': 15000,
            'primary_language': 'Python',
            'total_contributors': 12,
            'stars': 450
        },
        'code_quality_metrics': {
            'overall_score': 78,
            'grade': 'B+',
            'issues_identified': ['No CI/CD workflows', 'Limited test coverage']
        },
        'security_assessment': {
            'security_score': 85,
            'security_grade': 'A-',
            'risk_level': 'Low',
            'vulnerabilities_found': ['No security policy document']
        },
        'performance_indicators': {
            'overall_performance_score': 72,
            'performance_grade': 'B-'
        },
        'technical_debt': {
            'total_technical_debt_score': 45,
            'debt_level': 'Medium',
            'estimated_remediation_cost': '$15,000 - $30,000'
        },
        'recommendations': [
            {
                'category': 'Testing',
                'priority': 'High',
                'recommendation': 'Implement comprehensive test suite',
                'business_impact': 'Reduces bugs and deployment risks',
                'implementation_cost': '$4,000 - $8,000'
            },
            {
                'category': 'Security',
                'priority': 'Medium',
                'recommendation': 'Add security policy and scanning',
                'business_impact': 'Prevents security issues',
                'implementation_cost': '$2,000 - $4,000'
            }
        ],
        'business_impact': {
            'estimated_project_value': 125000,
            'monetization_potential': {
                'monetization_score': 65,
                'potential_level': 'Medium',
                'estimated_annual_revenue': '$25,000 - $100,000'
            }
        },
        'executive_summary': {
            'overall_health_score': 75.5,
            'health_grade': 'B',
            'investment_priority': 'Strategic Improvement',
            'financial_impact': {
                'estimated_roi': '180.5%',
                'payback_period': '6-12 months'
            }
        },
        'analysis_metadata': {
            'estimated_value': '$3,200'
        }
    }
    
    print("âœ… Sample analysis results generated")
    print(f"ðŸ“Š Overall Health Score: {sample_results['executive_summary']['overall_health_score']}%")
    print(f"ðŸ’° Estimated Analysis Value: {sample_results['analysis_metadata']['estimated_value']}")
    print(f"ðŸŽ¯ Investment Priority: {sample_results['executive_summary']['investment_priority']}")
    
    return sample_results

if __name__ == "__main__":
    print("ðŸš€ Eliza Premium Code Analysis Service Initialized")
    print("ðŸ’° Ready to generate revenue for the DAO!")
    print("\n" + generate_service_menu())
    
    # Test the system
    test_results = test_premium_analyzer()
    print(f"\nâœ… Premium analyzer tested successfully!")
    print(f"ðŸ’¼ Ready for client engagements!")
