# XMRT Feedback Integration System
# Integrates conversation feedback into autonomous cycle generation
# This bridges the gap between user conversations and autonomous learning

import json
import requests
from datetime import datetime
from typing import Dict, List, Any
import os

class ConversationFeedbackIntegrator:
    """Integrates conversation feedback into autonomous cycle priorities"""
    
    def __init__(self):
        self.knowledge_api = "https://xmrt-io.onrender.com"
        self.feedback_cache = {}
        self.priority_adjustments = {}
        self.conversation_insights = []
        
        # Load existing autonomous state
        self.load_autonomous_state()
        
    def load_autonomous_state(self):
        """Load current autonomous state and priorities"""
        try:
            with open('eliza_state.json', 'r') as f:
                self.autonomous_state = json.load(f)
        except FileNotFoundError:
            self.autonomous_state = {
                "cycle_count": 0,
                "last_run": "",
                "priorities": {
                    "analytics": 1.0,
                    "development": 1.0,
                    "marketing": 1.0,
                    "mining": 1.0,
                    "browser": 1.0,
                    "social_media": 1.0
                }
            }
    
    def fetch_conversation_feedback(self) -> Dict[str, Any]:
        """Fetch feedback from conversation system via Knowledge Bridge"""
        
        try:
            # In a real implementation, this would connect to the conversation feedback system
            # For now, we'll simulate based on Knowledge Bridge usage patterns
            
            # Check which categories are being accessed most frequently
            stats_response = requests.get(f"{self.knowledge_api}/api/knowledge/stats", timeout=30)
            
            if stats_response.status_code == 200:
                stats = stats_response.json()
                
                # Simulate conversation feedback based on API usage
                feedback = {
                    "timestamp": datetime.now().isoformat(),
                    "conversation_patterns": {
                        "high_interest_categories": ["development", "analytics"],
                        "knowledge_gaps": ["marketing", "social_media"],
                        "user_pain_points": ["Need more recent development updates"],
                        "requested_features": ["Better progress tracking"]
                    },
                    "priority_suggestions": {
                        "development": 1.3,  # High user interest
                        "analytics": 1.2,    # Moderate interest
                        "marketing": 0.8,    # Lower priority
                        "mining": 1.0,       # Standard
                        "browser": 1.1,      # Slight increase
                        "social_media": 0.9  # Slight decrease
                    }
                }
                
                return feedback
            else:
                print(f"‚ö†Ô∏è Could not fetch conversation feedback: {stats_response.status_code}")
                return {}
                
        except Exception as e:
            print(f"‚ùå Error fetching conversation feedback: {e}")
            return {}
    
    def analyze_conversation_patterns(self, feedback: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze conversation patterns to determine priority adjustments"""
        
        if not feedback:
            return {}
        
        patterns = feedback.get('conversation_patterns', {})
        
        analysis = {
            "priority_changes": {},
            "new_focus_areas": [],
            "task_adjustments": []
        }
        
        # Boost priorities for high-interest categories
        high_interest = patterns.get('high_interest_categories', [])
        for category in high_interest:
            analysis["priority_changes"][category] = {
                "adjustment": 0.2,
                "reason": "High user conversation interest"
            }
        
        # Address knowledge gaps
        knowledge_gaps = patterns.get('knowledge_gaps', [])
        for category in knowledge_gaps:
            analysis["new_focus_areas"].append({
                "category": category,
                "action": "increase_content_generation",
                "priority": "medium"
            })
        
        # Convert pain points to tasks
        pain_points = patterns.get('user_pain_points', [])
        for pain_point in pain_points:
            analysis["task_adjustments"].append({
                "task": f"Address user concern: {pain_point}",
                "category": "development",
                "priority": "high"
            })
        
        return analysis
    
    def update_autonomous_priorities(self, analysis: Dict[str, Any]) -> bool:
        """Update autonomous system priorities based on conversation analysis"""
        
        try:
            # Update priority weights
            priority_changes = analysis.get('priority_changes', {})
            
            for category, change in priority_changes.items():
                if category in self.autonomous_state.get('priorities', {}):
                    current_priority = self.autonomous_state['priorities'][category]
                    adjustment = change.get('adjustment', 0)
                    new_priority = max(0.1, min(2.0, current_priority + adjustment))
                    
                    self.autonomous_state['priorities'][category] = new_priority
                    
                    print(f"üéØ Updated {category} priority: {current_priority:.2f} ‚Üí {new_priority:.2f}")
            
            # Update autonomous state file
            self.autonomous_state['last_feedback_integration'] = datetime.now().isoformat()
            
            with open('eliza_state.json', 'w') as f:
                json.dump(self.autonomous_state, f, indent=2)
            
            print("‚úÖ Autonomous priorities updated successfully!")
            return True
            
        except Exception as e:
            print(f"‚ùå Error updating autonomous priorities: {e}")
            return False
    
    def generate_priority_config(self) -> Dict[str, Any]:
        """Generate updated configuration for next autonomous cycle"""
        
        priorities = self.autonomous_state.get('priorities', {})
        
        # Create task overrides based on priorities
        task_overrides = {}
        
        # Find highest priority categories
        sorted_priorities = sorted(priorities.items(), key=lambda x: x[1], reverse=True)
        
        for i, (category, priority) in enumerate(sorted_priorities[:3]):  # Top 3 priorities
            if priority > 1.1:  # Above normal priority
                task_overrides[f"{category}_action"] = f"Enhanced {category} analysis and improvement"
        
        config = {
            "mode": "productive",
            "fake_tasks_disabled": True,
            "conversation_feedback_integrated": True,
            "priority_weights": priorities,
            "task_override": task_overrides,
            "feedback_integration_timestamp": datetime.now().isoformat()
        }
        
        return config
    
    def integrate_feedback_into_next_cycle(self) -> bool:
        """Main integration function - call this before each autonomous cycle"""
        
        print("üîÑ INTEGRATING CONVERSATION FEEDBACK INTO AUTONOMOUS CYCLE")
        print("=" * 60)
        
        # Step 1: Fetch conversation feedback
        print("1Ô∏è‚É£ Fetching conversation feedback...")
        feedback = self.fetch_conversation_feedback()
        
        if not feedback:
            print("‚ö†Ô∏è No conversation feedback available")
            return False
        
        # Step 2: Analyze patterns
        print("2Ô∏è‚É£ Analyzing conversation patterns...")
        analysis = self.analyze_conversation_patterns(feedback)
        
        # Step 3: Update priorities
        print("3Ô∏è‚É£ Updating autonomous priorities...")
        priorities_updated = self.update_autonomous_priorities(analysis)
        
        # Step 4: Generate new config
        print("4Ô∏è‚É£ Generating priority-adjusted configuration...")
        new_config = self.generate_priority_config()
        
        # Step 5: Save updated config
        try:
            with open('feedback_integrated_config.json', 'w') as f:
                json.dump(new_config, f, indent=2)
            
            print("‚úÖ Feedback-integrated configuration saved!")
            
            # Also update main config with priority hints
            try:
                with open('config.json', 'r') as f:
                    main_config = json.load(f)
                
                main_config['conversation_feedback_applied'] = True
                main_config['priority_weights'] = new_config['priority_weights']
                main_config['last_feedback_integration'] = new_config['feedback_integration_timestamp']
                
                with open('config.json', 'w') as f:
                    json.dump(main_config, f, indent=2)
                
                print("‚úÖ Main configuration updated with feedback priorities!")
                
            except Exception as e:
                print(f"‚ö†Ô∏è Could not update main config: {e}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error saving configuration: {e}")
            return False
    
    def get_integration_status(self) -> Dict[str, Any]:
        """Get current status of feedback integration"""
        
        return {
            "autonomous_state": self.autonomous_state,
            "last_integration": self.autonomous_state.get('last_feedback_integration', 'Never'),
            "current_priorities": self.autonomous_state.get('priorities', {}),
            "integration_active": True
        }

# Initialize the integrator
feedback_integrator = ConversationFeedbackIntegrator()

def run_feedback_integration():
    """Run the feedback integration process"""
    
    print("üöÄ RUNNING CONVERSATION FEEDBACK INTEGRATION")
    print("=" * 60)
    
    # Get current status
    status = feedback_integrator.get_integration_status()
    print(f"üìä Current Integration Status:")
    print(f"   Last Integration: {status['last_integration']}")
    print(f"   Integration Active: {status['integration_active']}")
    
    # Run integration
    success = feedback_integrator.integrate_feedback_into_next_cycle()
    
    if success:
        print("\nüéâ FEEDBACK INTEGRATION COMPLETE!")
        print("‚úÖ Conversation patterns analyzed")
        print("‚úÖ Autonomous priorities updated")
        print("‚úÖ Configuration generated for next cycle")
        
        # Show updated priorities
        updated_status = feedback_integrator.get_integration_status()
        priorities = updated_status['current_priorities']
        
        print("\nüéØ UPDATED PRIORITIES:")
        for category, priority in priorities.items():
            status_emoji = "üî•" if priority > 1.2 else "‚ö°" if priority > 0.9 else "üí§"
            print(f"   {status_emoji} {category.title()}: {priority:.2f}")
        
        return True
    else:
        print("\n‚ö†Ô∏è FEEDBACK INTEGRATION INCOMPLETE")
        print("Check the errors above for details")
        return False

if __name__ == "__main__":
    # Run the integration
    run_feedback_integration()
